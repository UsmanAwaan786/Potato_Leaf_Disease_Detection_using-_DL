import tensorflow as tf
from tensorflow.keras import models,layers
import matplotlib.pyplot as plt 
dataset=tf.keras.preprocessing.image_dataset_from_directory(
    "PlantVillage",
     shuffle=True,
    image_size=(256,256),
    batch_size=32)

class_names=dataset.class_names

def get_dataset_partitions_tf(ds,train_split=0.8,val_ds=0.1,test_split=0.1,shuffle=True,shuffle_size=10000):
    ds_size=len(ds)
    if shuffle:
        ds=ds.shuffle(shuffle_size, seed=12)
    train_size=int(train_split*ds_size)
    val_size=int(val_ds*ds_size)
    train_ds=ds.take(train_size)
    val_ds=ds.skip(train_size).take(val_size)
    test_ds=ds.skip(train_size).skip(val_size)
    
    return train_ds, val_ds,test_ds

train_ds,val_ds,test_ds=get_dataset_partitions_tf(dataset)

train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)

resize_and_rescale=tf.keras.Sequential([
    layers.experimental.preprocessing.Resizing(256,256),
    layers.experimental.preprocessing.Rescaling(1.0/256)
])


data_augmentaion=tf.keras.Sequential([
    layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
      # layers.experimental.preprocessing.RandomRotation(0.1)
])

input_shape=(32,256,256,3)
n_classes=3
model=models.Sequential([
     resize_and_rescale,
     data_augmentaion,
     layers.Conv2D(32,(3,3),activation='relu', input_shape=input_shape),
     layers.MaxPooling2D((2,2)),
     layers.Conv2D(64,kernel_size=(3,3),activation='relu'),
     layers.MaxPooling2D((2,2)),
     layers.Conv2D(64,kernel_size=(3,3),activation='relu'),
     layers.MaxPooling2D((2,2)),
     layers.Conv2D(64,(3,3),activation='relu'),
     layers.MaxPooling2D((2,2)),
     layers.Conv2D(64,(3,3),activation='relu'),
     layers.MaxPooling2D((2,2)),
     layers.Conv2D(64,(3,3),activation='relu'),
     layers.MaxPooling2D((2,2)),
     layers.Flatten(),
     layers.Dense(64,activation='relu'),
     layers.Dense(n_classes,activation='softmax'),
 ])
model.build(input_shape=input_shape)


model.compile(
optimizer='adam',
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
metrics=['accuracy']
)

history=model.fit(
train_ds,
    epochs=30,
    batch_size=32,
    verbose=1,
    validation_data=val_ds
)

score=model.evaluate(test_ds)
print(score)


acc=history.history["accuracy"]
val_acc=history.history["val_accuracy"]
loss=history.history["loss"]
val_loss=history.history["val_loss"]

# Plot of Training and Validation Accuracy and Loss

# plt.figure(figsize=(8,8))
# plt.subplot(1,2,1)
# plt.plot(range(30),acc,label="Training Accuracy")
# plt.plot(range(30),val_acc,label="Validation Accuracy")
# plt.legend(loc='lower right')
# plt.title("Training and Validation Accuracy")

# plt.subplot(1,2,2)
# plt.plot(range(30),loss,label="Training Loss")
# plt.plot(range(30),val_loss,label="Validation Loss")
# plt.legend(loc='upper right')
# plt.title("Training and Validation Loss")



# Checking a model by giving test data
import numpy as np
for images_batch, labels_batch in test_ds.take(6):
    first_image=images_batch[0].numpy().astype("uint8")
    first_label=labels_batch[0].numpy()
    print("first image to predict")
    plt.imshow(first_image)
    print("first image's actual label",class_names[first_label])
    
    batch_prediction=model.predict(images_batch)

    print("Predicted Label",class_names[np.argmax(batch_prediction[0])])

#saving a model 
model_version=2
model.save(f"../models/{model_version}")

#loading a model
loaded_model = tf.keras.models.load_model("../models/2",compile=True)




